---
layout: post
comments: true
title:  "Lip Reading: Research, Hackathons and Accessbility"
excerpt: "Test"
date:   2025-05-07 00:00:00
categories: [Hackathons]
tags: ["Lip Reading", "Hackathons"]
---

## Table of Contents

* TOC
{:toc}

## Introduction

This post is the first of a two part series exploring my journey involving
modern lip reading AI. The posts are arranged as follows:
- Part 1: Background and Uusing lip reading to win $100k at a hackathon!
- Part 2: Another hackathon improving upon real-world performance

## Background

During the later stage of my MEng Computer Science course in 2023, I was doing a module on
action recognition. This involved using computer vision to build up basic datasets and
classify actions.
However, I wanted to go a step further and explore the state-of-the-art in an interesting
and novel application of action recognition.

Here I stumbled upon visual speech recognition, otherwise known as "lip-reading".
At first, I thought that 

## References

- [Lip2Seq](https://github.com/MiscellaneousStuff/comp-vis-avhubert/blob/main/paper.pdf)
- [Lip2Nav Presentatiuon](https://github.com/MiscellaneousStuff/comp-vis-avhubert/blob/main/paper.pdf)